{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# TD 04 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\clemm\\AppData\\Local\\Temp\\ipykernel_49216\\3999586055.py\", line 6, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des données\n",
    "\n",
    "- un cercle de rayon 3 centré en (0,0)\n",
    "- une sinusoide d'amplitude 1 et de fréquence 6 $\\pi$\n",
    "- une bande délimitée par deux  sinusoïdes (répartition graduelle en tanh)\n",
    "\n",
    "\n",
    "Les données seront légerement perturbées par un bruit gaussien d'amplitude 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return N data drawn according to the wanted density\n",
    "def f_data(N, model='circle'):\n",
    "  eps = np.random.randn(N) # Gaussian noise\n",
    "\n",
    "  if model == 'circle':\n",
    "    t = np.random.rand(N)# Uniform\n",
    "    # Circle of radius 3 and centered in 0: x = R*cos(2pit), y = Rsin(2pit)\n",
    "    x = 3*np.cos(2*np.pi*t) + eps\n",
    "    y = 3*np.sin(2*np.pi*t) + eps # Using the same noise (we could also use another one for y)\n",
    "    return np.column_stack((x,y))\n",
    "\n",
    "  z1 = 3*np.random.randn(N) # Gaussian\n",
    "  if model == 'simple_sin':\n",
    "    # Sinusoid of amplitude 1 and frequency 6pi\n",
    "    y = np.sin(6*np.pi*z1) + eps\n",
    "    return np.column_stack((z1,y))\n",
    "  \n",
    "  elif model == 'double_sin':\n",
    "    z2 = 3*np.random.randn(N) # Gaussian (2)\n",
    "    return np.column_stack((z1+0.1*eps,np.cos(z1)+np.tanh(z2)+0.1*eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design des réseaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générateur, il doit être en mesure de produire des données pour notre problème.\n",
    "\n",
    "Première couche est l'espace du latent `sz_latent`, une couche cachée de taille `sz_hidden` et une couche de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, sz_latent,sz_hidden):\n",
    "    super(Generator, self).__init__()\n",
    "    self.fc1 = nn.Linear(sz_latent,sz_hidden)\n",
    "    self.fc2 = nn.Linear(sz_hidden,sz_hidden)\n",
    "    self.fout = nn.Linear(sz_hidden,2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fout(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau critique, est un MLP qui doit déterminer si les données sont réelles ou fausses.\n",
    "\n",
    "Il comporte trois couches, la première étant de taille `sz`. La taille des deux couches suivantes est deux fois moindre que sa précédente. La décision finale est la probabilité que la donnée d’entrée soit réelle (ou fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, sz):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.fc1 = nn.Linear(2,sz)\n",
    "    self.fc2 = nn.Linear(sz,int(sz/2))\n",
    "    self.fc3 = nn.Linear(int(sz/2),int(sz/4))\n",
    "    self.fout = nn.Linear(int(sz/4),1) # un seul neurone pour la proba [0,1]\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = torch.sigmoid(self.fout(x)) # decision (proba)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs):\n",
    "  for epoch in range(epochs):\n",
    "      for ii in range(20):  # train D for 20 steps\n",
    "        D.zero_grad() # could be d_optimizer.zero_grad() since the optimizer is specific to the model\n",
    "\n",
    "        # train D on real data\n",
    "        d_real_data = (torch.FloatTensor(f_data(batch_size,model))).to(device)\n",
    "        d_real_decision = D(d_real_data)\n",
    "        d_real_error = criterion(d_real_decision, torch.ones([batch_size,1]).to(device))\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        # train D on fake data\n",
    "        d_gen_seed = (torch.FloatTensor( torch.randn(batch_size,latent_dim ) )).to(device)  # TODO rand ou randn ?\n",
    "        d_fake_data = G( d_gen_seed ).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(d_fake_data)\n",
    "        d_fake_error = criterion(d_fake_decision, torch.zeros([batch_size,1]).to(device))\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "        dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "      for ii in range(20):  # train G for 20 steps\n",
    "        G.zero_grad()\n",
    "\n",
    "        g_gen_seed = (torch.FloatTensor( torch.randn(batch_size,latent_dim ))).to(device)\n",
    "        g_fake_data = G( g_gen_seed )\n",
    "        dg_fake_decision = D(g_fake_data)\n",
    "        g_error = criterion(dg_fake_decision, torch.ones([batch_size,1]).to(device))  # Train G to pretend it's genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "        ge = extract(g_error)[0]\n",
    "      if epoch % 20 ==0:\n",
    "        print(\"Epoch %s: D (%1.4f real_err, %1.4f fake_err) G (%1.4f err) \" % (epoch, dre, dfe, ge))\n",
    "\n",
    "      if epoch % 60 == 0:\n",
    "        g_gen_seed = (torch.FloatTensor( torch.randn(1000,latent_dim ))).to(device)\n",
    "        g_fake_data = G( g_gen_seed ).detach().to(\"cpu\")\n",
    "        \n",
    "\n",
    "        # plot ground truth\n",
    "        if model == \"circle\":\n",
    "          t=np.arange(0,1.1,0.025)\n",
    "          plt.plot(3*np.cos(t*2*np.pi),3*np.sin(t*2*np.pi), 'r-')\n",
    "        if model == \"simple_sin\":\n",
    "          xx = np.arange(-3,3,0.25)\n",
    "          plt.plot(3*xx,np.cos(3*xx), 'r-')\n",
    "        if model == \"double_sin\":\n",
    "          xx = np.arange(-3,3,0.25)\n",
    "          plt.plot(3*xx,np.cos(3*xx)+1, 'r-')\n",
    "          plt.plot(3*xx,np.cos(3*xx)-1, 'r-')\n",
    "\n",
    "        plt.plot(g_fake_data[:,0],g_fake_data[:,1],'b.')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_params_training(latent_dim = 2):\n",
    "    G = Generator(latent_dim,32).to(device)\n",
    "    D = Discriminator(32).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=1e-3, momentum=0.8)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=1e-3, momentum=0.8)\n",
    "    # Adam optimizer\n",
    "    #d_optimizer = optim.Adam(D.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "    #g_optimizer = optim.Adam(G.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "    return G, D, criterion, d_optimizer, g_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"circle\"\n",
    "# model = \"simple_sin\"\n",
    "# model = \"double_sin\"\n",
    "latent_dim = 2\n",
    "# epochs = 3000\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "G, D, criterion, d_optimizer, g_optimizer = get_params_training(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clemm\\AppData\\Local\\Temp\\ipykernel_49216\\3543923149.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return v.data.storage().tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.7813 real_err, 0.5758 fake_err) G (0.8248 err) \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs)\u001b[0m\n\u001b[0;32m     54\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mxx,np\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mxx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mxx,np\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mxx)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_fake_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mg_fake_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3830\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3831\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3832\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3833\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3834\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3835\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\axes\\_base.py:483\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    480\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 483\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\cbook.py:1351\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43m_unpack_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\matplotlib\\cbook.py:2361\u001b[0m, in \u001b[0;36m_unpack_to_numpy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m xtmp\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_jax_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_tensorflow_array(x):\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# using np.asarray() instead of explicitly __array__(), as the latter is\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;66;03m# only _one_ of many methods, and it's the last resort, see also\u001b[39;00m\n\u001b[0;32m   2359\u001b[0m     \u001b[38;5;66;03m# https://numpy.org/devdocs/user/basics.interoperability.html#using-arbitrary-objects-in-numpy\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m     \u001b[38;5;66;03m# therefore, let arrays do better if they can\u001b[39;00m\n\u001b[1;32m-> 2361\u001b[0m     xtmp \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# In case np.asarray method does not return a numpy array in future\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xtmp, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\clemm\\miniconda3\\envs\\pf-env\\lib\\site-packages\\torch\\_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Que se passe t'il si l'on réduit la dimension de l'espace latent ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"circle\"\n",
    "# model = \"simple_sin\"\n",
    "model = \"double_sin\"\n",
    "latent_dim = 1\n",
    "epochs = 3000\n",
    "# epochs = 2000\n",
    "G, D, criterion, d_optimizer, g_optimizer = get_params_training(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
